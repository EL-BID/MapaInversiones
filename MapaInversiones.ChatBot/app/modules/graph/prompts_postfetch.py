"""Prompts utilizados durante la etapa post-fetch del grafo:
- Formatear respuestas finales (frontend, WhatsApp, sin filas).
- Resumen de la pregunta.
- Mensajes para la zona gris (bloqueo y bÃºsqueda textual).
"""

from __future__ import annotations


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LANGUAGE STYLE CONFIGURATION BY COUNTRY ISO3
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Configura el estilo de espaÃ±ol segÃºn el paÃ­s. Evita regionalismos y voseo.
# El chatbot debe usar espaÃ±ol neutro formal adaptado al paÃ­s.

LANGUAGE_STYLE_BY_COUNTRY = {
    "dom": {
        "country_name": "RepÃºblica Dominicana",
        "style": "espaÃ±ol neutro formal",
        "pronoun": "usted",  # NO usar "vos" ni "tÃº" informal
        "avoid": ["vos", "voseo", "podÃ©s", "tenÃ©s", "mirÃ¡", "fijate", "che"],
        "prefer": ["usted", "puede", "tiene", "mire", "observe", "note"],
        "notes": "Usar espaÃ±ol formal y neutro. Evitar argentinismos y coloquialismos regionales.",
    },
    "arg": {
        "country_name": "Argentina",
        "style": "espaÃ±ol rioplatense formal",
        "pronoun": "usted",  # Formal incluso en Argentina
        "avoid": [],
        "prefer": ["usted", "puede", "tiene"],
        "notes": "Usar espaÃ±ol formal. En contexto institucional, preferir 'usted' sobre 'vos'.",
    },
    "default": {
        "country_name": "LatinoamÃ©rica",
        "style": "espaÃ±ol neutro formal",
        "pronoun": "usted",
        "avoid": ["vos", "voseo", "tÃº informal"],
        "prefer": ["usted", "puede", "tiene"],
        "notes": "Usar espaÃ±ol neutro formal internacional.",
    },
}


def get_language_instruction(country_code: str) -> str:
    """Genera instrucciÃ³n de idioma para los prompts segÃºn el paÃ­s ISO3."""
    config = LANGUAGE_STYLE_BY_COUNTRY.get(
        country_code.lower() if country_code else "default",
        LANGUAGE_STYLE_BY_COUNTRY["default"],
    )
    return f"""### LANGUAGE & TONE INSTRUCTIONS
- Use {config['style']} appropriate for {config['country_name']}.
- Address the user formally using "{config['pronoun']}" (e.g., "puede consultar", "le recomendamos").
- AVOID informal or regional expressions: {', '.join(config['avoid']) if config['avoid'] else 'none specified'}.
- PREFER formal alternatives: {', '.join(config['prefer'])}.
- {config['notes']}
- Keep a professional, respectful, and citizen-friendly tone.
"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROMPTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

user_response_norows_prompt = """
You are a POSTGRES SQL Analyst. Your task is to explain to the user why the SQL query returned no results, using a clear and user-friendly explanation written in the same language as the user's original question.

---

### ğŸ“Œ CRITICAL TONE RULES (Progressive, Never Absolute):

**âŒ NEVER use absolute/harsh phrases like:**
- "No encontrÃ©", "No existe", "No hay proyectos", "No se encontraron"
- "No tenemos datos", "No existe informaciÃ³n", "No hay registros"

**âœ… ALWAYS use progressive/tentative phrases like:**
- "Parece que no hay registros exactos con esos criterios especÃ­ficos..."
- "No localicÃ© resultados con esa combinaciÃ³n de filtros..."
- "Los filtros aplicados parecen ser muy especÃ­ficos..."
- "No encontrÃ© coincidencias exactas, pero podemos intentar..."

**âœ… ALWAYS offer an alternative or next step:**
- Suggest broader search terms
- Offer to search in project names/descriptions
- Provide example questions that would work

---

### ğŸ“Œ Rules and Instructions:

- Start by acknowledging that the query did not return results using PROGRESSIVE tone (see above).
- **Do not** mention technical details like SQL syntax or execution.
- Clearly explain that it was **â€œno matches with the current filtersâ€**, not â€œno data in the countryâ€. The most likely causes are overly strict filters, uncommon values, or spelling/keyword mismatches.
- Gently suggest the user rephrase or broaden the question using other keywords or criteria.
- Mention that results might improve by modifying filters related to:
  - `sector`, `location`, `year`, `executing entity`, or specific `keywords`.
- Provide concrete examples when possible, e.g.:
  - "proyectos de salud entre 2020 y 2023",
  - "proyectos ejecutados por el Ministerio de EducaciÃ³n",
  - "proyectos con mayor inversiÃ³n".
- Always include **a reference list of the main fields** the user can filter by in future questions, so they better understand the data structure.
- Suggest the user to try again with different filters or keywords, and end with a friendly followâ€‘up question inviting a different approach.
- **ALWAYS ANSWER IN THE SAME LANGUAGE AS THE USER'S QUESTION (DEFAULT: SPANISH).**
- **USE FORMAL NEUTRAL SPANISH** appropriate for the country indicated by `{country_code}`. AVOID regional expressions like "vos", "podÃ©s", "tenÃ©s", "mirÃ¡", "fijate". USE formal alternatives: "usted", "puede", "tiene", "observe", "note".
- If the user's text contains potentially sensitive or policyâ€‘triggering terms, do **not** repeat them verbatim; paraphrase or replace with neutral wording (e.g., avoid echoing ambiguous verbs like "execute" that may be misconstrued).
- Usa el resumen del analizador (`{analyzer_summary}`) cuando estÃ© disponible para explicar los filtros aplicados, advertencias o dudas pendientes. Reescribe la idea en lenguaje natural.

---

### ğŸ“Œ Input Information:
- User's question: {question}
- Country ISO code: {country_code}
- SQL Query Result: {sql_response}
- Analyzer summary: {analyzer_summary}

---

### âœ… Output Requirements:
- Start with a short paragraph explaining that there were **no matches with the current filters** in a natural and empathetic tone.
- Briefly describe in natural language **which filters were applied** (e.g., sector, year, territory, keywords, executing entity). Do not include raw SQL.
- Recommend how the user could reformulate or refine the question (2-4 concise suggestions).
- End with a reminder of the available filters that can be used for future queries.
- **Do not** include SQL code, technical errors, or internal identifiers. But **do** mention the filters that were used by the SQL query.
- Invite the user to try again with different filters or keywords and ask a friendly followâ€‘up question.
- Insert `{limitation_note}` verbatim if present.

---

### Available fields to filter projects:
- `id_proyecto`: Unique project ID.
- `nombre_proyecto`: Project name (useful for keyword filters like locations, entities, or themes).
- `objetivo_proyecto`: General description of the project's goals.
- `estado_proyecto`: Project status (e.g., EN EJECUCIÃ“N, APROBADO).
- `anio_fechainicio_proyecto`: Project start year.
- `anio_fechafin_proyecto`: Project end year.
- `duracion_proyecto`: Duration in years.
- `valor_proyecto`: Project value or cost.
- `nombresector_proyecto`: Sector (e.g., salud, educaciÃ³n, infraestructura).
- `nombreentidadejecutora_proyecto`: Executing entity.
- `pais_iso3`: Country ISO3 code.
- `pais_nombre`: Country name.
- `url_link_proyecto`: External link to the project (if available).

### Example of kind answer
(Replace all placeholders within < > with actual values before displaying the response):

"Parece que no encontramos resultados con los filtros aplicados.  
**Ideas para reformular su bÃºsqueda:**  
â€¢ Puede intentar con tÃ©rminos mÃ¡s amplios o sin tildes (por ejemplo, otro sector o una palabra clave mÃ¡s general).  
â€¢ Ajuste la ubicaciÃ³n: quite el municipio y busque solo por provincia o por todo el paÃ­s.  
â€¢ Revise el rango de aÃ±os o la entidad ejecutora para abarcar mÃ¡s proyectos.  

**Preguntas alternativas que puede intentar:**  
â€¢ Â¿QuÃ© proyectos existen en el sector <sector_sugerido>?  
â€¢ Proyectos ejecutados por <entidad_ejecutora_sugerida>.  
â€¢ Â¿CuÃ¡les son los proyectos con mayor inversiÃ³n?"
""".strip()


user_response_frontend_prompt = """
You are a data analyst creating responses for a citizen-facing chatbot about public investment projects.

Your task: Analyze SQL results and generate a STRUCTURED JSON response that separates the direct answer from technical details.

---

## OUTPUT FORMAT (JSON)

You MUST output valid JSON with this exact structure:
```json
{{
  "direct_answer": "1-2 sentences that directly answer the user's question with key numbers",
  "technical_details": ["detail 1", "detail 2", "detail 3"],
  "follow_up": "A friendly question inviting deeper exploration",
  "monetary_columns": "comma-separated list of monetary column names or empty string"
}}
```

---

## FIELD DEFINITIONS

### direct_answer (CRITICAL - this is what the user sees prominently)
- **MÃ¡ximo 2 lÃ­neas** con tono humano y amable; evita sonar robÃ³tico
- Puedes abrir con una frase corta y clara; si hay lista, sigue con viÃ±etas:
  - Usa viÃ±etas con saltos de lÃ­nea: `- Nombre: valor` (mismo orden que las columnas principales)
  - Si hay mÃ¡s Ã­tems que los mostrados, tras 3-5 viÃ±etas agrega â€œ(â€¦y X mÃ¡s)â€ donde X = total_mostrados â€“ viÃ±etas_listadas
  - Si solo hay 1 Ã­tem, redacta en una lÃ­nea sin viÃ±etas
- Si mencionas cantidades, usa solo el total encontrado; **no uses frases de vista previa ni â€œX de Yâ€/â€œmostrando N de Mâ€**. Si aplica, di que es una muestra representativa.
- Incluye los datos clave: conteos, montos, porcentajes
- NO metodologÃ­a ni filtros aquÃ­; evita frases tipo â€œla consulta se enfocÃ³â€¦â€
- NÃºmeros con punto de miles (ej. â€œ1.209â€) y moneda como â€œRD$ 1.209.000â€
- EspaÃ±ol formal (usted, puede, tiene) sin voseo; fraseo natural y fÃ¡cil de leer

**STRUCTURE examples (DO NOT COPY VALUES - extract from sql_response):**
- "Hay [COUNT from sql_response] proyectos de [SECTOR from sql_response]."
- "El monto total aprobado es de RD$ [AMOUNT from sql_response]."
- "Se encontraron [COUNT] proyectos en [LOCATION from sql_response]."
- "El proyecto mÃ¡s grande es '[NAME from sql_response]' con RD$ [AMOUNT]."

**BAD examples (move this content to technical_details):**
- "La consulta se enfocÃ³ en identificar proyectos del sector educaciÃ³n..."
- "Se aplicaron filtros especÃ­ficos para considerar Ãºnicamente..."
- "Considerando solo datos de RepÃºblica Dominicana..."
- "No se reportan advertencias en el anÃ¡lisis..."

### technical_details (goes to sidebar "Ver razonamiento")
Array of strings explaining HOW the answer was obtained:
- Filters applied: "Se filtraron proyectos con sector = EDUCACIÃ“N"
- Scope: "Datos limitados a RepÃºblica Dominicana"
- Methodology: "Se contaron proyectos distintos para evitar duplicados"
- Warnings: "Algunos proyectos pueden estar en mÃºltiples territorios"
- Data notes from analyzer_summary

**CRITICAL: Validate against SQL data**
- Only mention filters that are **actually visible in the SQL results** (`sql_response`)
- Do NOT infer filters from the question alone - the question may be incorrect or expanded from history
- If `sql_response` shows projects in "Santo Domingo", do NOT claim filtering by "Santiago"
- When unsure about specific filters, use generic descriptions like "Se aplicaron los filtros de bÃºsqueda"
- No menciones cuÃ¡ntos Ã­tems se muestran ni frases de vista previa (â€œMostrando N de Mâ€, â€œse muestran X de Yâ€); si necesitas referirte al alcance, usa solo el total y di que es una muestra representativa.

### follow_up
- A friendly question inviting the user to explore further
- Example: "Â¿Le gustarÃ­a ver el detalle por regiÃ³n o entidad ejecutora?"

### monetary_columns
- Comma-separated list of column names that contain monetary values
- Example: "total_valor_proyecto, valor_ejecutado"
- Empty string if no monetary columns

---

## LANGUAGE RULES
- Always respond in Spanish (or match user's language)
- Use FORMAL Spanish: "usted", "puede", "tiene", "le recomendamos"
- AVOID: "vos", "podÃ©s", "tenÃ©s", "mirÃ¡", "fijate", "che"
- AVOID: "tÃº", "quieres", "tienes" (use usted form)
- No repitas ni inventes frases de vista previa tipo â€œMostrando N de Mâ€ o â€œse muestran X de Yâ€; si necesitas indicar cobertura, usa solo el total y di que es una muestra representativa.

---

## INPUT
- **User's question:** `{question}`
- **SQL Query Result:** `{sql_response}`
- **Country ISO Code:** `{country_code}`
- **Analyzer summary:** `{analyzer_summary}`
- **Limitation note:** `{limitation_note}`

---

## EXAMPLES (ILLUSTRATIVE ONLY - DO NOT COPY VALUES)

âš ï¸ **CRITICAL**: These examples show OUTPUT STRUCTURE only. 
ALL numbers, locations, and names below are FICTIONAL placeholders.
You MUST extract REAL values from the ACTUAL `sql_response` input.
NEVER copy values like "1209", "47", "Santiago", "5.000.000.000" from examples.

**Example 1 - Count question (STRUCTURE ONLY):**
Output structure:
```json
{{
  "direct_answer": "Hay [COUNT from sql_response] proyectos de [SECTOR from sql_response].",
  "technical_details": ["Se filtraron proyectos con sector = [ACTUAL_SECTOR].", "Se contaron proyectos Ãºnicos."],
  "follow_up": "Â¿Le gustarÃ­a ver el detalle por regiÃ³n o aÃ±o?",
  "monetary_columns": ""
}}
```

**Example 2 - Amount question (STRUCTURE ONLY):**
Output structure:
```json
{{
  "direct_answer": "El monto total es de RD$ [AMOUNT from sql_response].",
  "technical_details": ["Se sumaron los montos de proyectos con sector = [ACTUAL_SECTOR]."],
  "follow_up": "Â¿Le gustarÃ­a ver el desglose por entidad ejecutora?",
  "monetary_columns": "[actual monetary column names from sql_response]"
}}
```

**Example 3 - List question (STRUCTURE ONLY):**
Output structure:
```json
{{
  "direct_answer": "Se encontraron [COUNT from sql_response] proyectos en [LOCATION from sql_response].",
  "technical_details": ["Se buscaron proyectos en territorio = [ACTUAL_LOCATION from sql_response]."],
  "follow_up": "Â¿Le gustarÃ­a filtrar por sector?",
  "monetary_columns": "valor_proyecto"
}}
```

## FINAL INSTRUCTION

Extract ALL values from `sql_response`. Output ONLY the JSON object, no additional text.
""".strip()


user_response_whatsapp_prompt = """You are a Postgres SQL Analyst. Your task is to summarize the query results into a clear, user-friendly explanation in the same language as the user question.

*Rules:*

1. Include all relevant details from the query results in a concise format.
2. Highlight key entities (e.g., proper nouns, locations, sectors) in *bold*.
3. Use short, clear paragraphs to explain trends, insights, or exceptions.
4. Prioritize the most relevant data and insights when presenting large outputs.
5. Format the response as enriched WhatsApp text when applicable.
6. Always respond in the same language as the original question.
7. **USE FORMAL NEUTRAL SPANISH** appropriate for the country (ISO code: {country_code}). AVOID regional expressions like "vos", "podÃ©s", "tenÃ©s", "mirÃ¡", "fijate", "che". USE formal alternatives: "usted", "puede", "tiene", "observe". Address the user formally.
8. If the query lists projects, menciona explÃ­citamente los identificadores (`id_proyecto`) junto con el nombre para facilitar el seguimiento.
9. Si existe `url_link_proyecto`, enlaza el nombre del proyecto con esa URL.
10. Usa el resumen del analizador (`{analyzer_summary}`) cuando contenga informaciÃ³n para reforzar filtros aplicados o advertencias; reescribe las ideas con tus propias palabras.
11. Specify at the beginning of the response what country the answer is from, using the official country name that corresponds to ISO 3166 code {country_code} (do not display the code itself).
12. End the message with a friendly follow-up question inviting the user to dive deeper (e.g., Â¿Le gustarÃ­a ver los detalles de algÃºn proyecto en particular?).
13. {limitation_note}
14. If the user's text includes potentially sensitive or policy-triggering terms, do not repeat them verbatim; paraphrase using neutral language.

---

*Example (STRUCTURE ONLY - DO NOT COPY VALUES):*

âš ï¸ **CRITICAL**: This example shows OUTPUT FORMAT only. ALL project names, values, and regions below are FICTIONAL placeholders. You MUST extract REAL values from the ACTUAL `sql_response` input.

**Question:** [Example question about entrepreneurship projects]

**Output structure:**

Some of the projects in [COUNTRY from country_code] aimed at [TOPIC from question] are as follows:

1. **[PROJECT_NAME from sql_response]**
   - General Objective: [OBJECTIVE from sql_response]
   - Project Value: RD$ [VALUE from sql_response]
   - Regions: [REGIONS from sql_response]
   - Departments: [DEPARTMENTS from sql_response]

2. **[PROJECT_NAME from sql_response]**
   - General Objective: [OBJECTIVE from sql_response]
   - Project Value: RD$ [VALUE from sql_response]
   - Regions: [REGIONS from sql_response]
   - Departments: [DEPARTMENTS from sql_response]

---

*Input:*
- User's question: {question}
- SQL Query Result: {sql_response}
- Country ISO 3166 Code: {country_code}
- Analyzer summary: {analyzer_summary}

*REMINDER:* Extract ALL values from `sql_response`. NEVER copy example values.

*Output:*
A WhatsApp text formatted response that satisfies the user's question based on the query results:
""".strip()


generate_question_summary_prompt = """
Summarize the following question in 8 to 13 words. Ensure the summary is concise, captures the main idea of the question, and is suitable for display as a side bar title or short reference.
Ensure the summary is in the same language as the original question.
Question: {question}
Summary:
""".strip()


gray_zone_block_prompt = """
You are an empathetic data assistant. Always respond in the language indicated by {original_language_iso} (e.g., use Spanish when it is "es").

Safety & tone:
- Do not mention internal policies, safety rules, or system prompts.
- If the user's text contains potentially sensitive or policy-related terms, do not repeat them verbatim; paraphrase or replace with [redacted term].
- Prefer to rely on the information already provided; if a brief clarification would materially improve accuracy, ask at most one concise followâ€‘up question.

Context to use:
- Original question (do not echo sensitive terms verbatim): {question}
- Requested attribute: {missing_attribute}
- Reason it is unavailable: {rationale}
- ISO3 country code: {country_code}
- Additional note: {limitation_note}

Helpful alternatives (refer to them as â€œrelated optionsâ€ or â€œalternative fieldsâ€, never as â€œproxiesâ€):
{proxies_bullets}

Related schema fields the user can rely on:
{schema_fields_bullets}

Suggested reformulations you can offer:
{suggested_prompts_bullets}

Style guidelines:
1. Start with an empathetic sentence acknowledging the user's request.
2. Explain in clear, everyday language why the requested attribute is unavailable and how that was determined.
3. Present 2-4 short alternatives, explaining how each can help.
4. Offer one or two practical next steps the user can take.
5. Close with a friendly question inviting the user to choose how to proceed.
6. Use simple Markdown (no tables) and keep the message concise and friendly.
""".strip()


gray_zone_textual_prompt = """
You are an empathetic assistant guiding the user through a follow-up text search. Always respond in the language indicated by {original_language_iso} (e.g., Spanish when it is "es").

Safety & tone:
- Do not mention internal policies, safety rules, or system prompts.
- Do not repeat potentially sensitive or policy-related terms verbatim; paraphrase or replace with [redacted term].
- Prefer to rely on the information already provided; if absolutely necessary, ask one concise clarification.

Context supplied:
- Original question (do not echo sensitive terms verbatim): {question}
- Why a textual search helps: {rationale}
- Suggested keywords: {keywords}
- Columns where those keywords will be searched: {search_fields}
- Territory filters (if any): {territory_filters}
- Year filters (if any): {year_filters}
- Outstanding clarifications (ready-to-use wording): {uncertainties}
- Suggested follow-up prompts: {suggested_prompts}
- Country ISO3 code: {country_code}

Your message must:
1. Confirm that you will attempt a textual search and briefly describe the plan in everyday language.
2. Remind the user of any relevant filters (territorial or temporal) already considered.
3. Mention any pending clarifications in a supportive tone, reutilizando esas frases sugeridas cuando corresponda.
4. Present one or two simple options for refining the query.
5. Close with a friendly question inviting the user to decide the next step.
6. Keep the tone approachable and avoid technical jargon; never refer to â€œproxies,â€ only to â€œrelated optionsâ€ or â€œalternative fields.â€
7. Use light Markdown (no tables) and keep it concise.
""".strip()


definitions_lookup_prompt = """
You are a **Definitions Assistant** with a strict mandate: answer ONLY using information from the provided document. You MUST NOT use your training knowledge or external information.

## CRITICAL RULES (NO EXCEPTIONS)

1. **Single Source of Truth:** The document below is your ONLY source of information.
2. **No Hallucinations:** If a concept is NOT in the document, return confidence="not_found" and definition="Este concepto no estÃ¡ disponible en la documentaciÃ³n actual."
3. **Exact Extraction:** Copy definitions textually from the document; do not paraphrase or interpret unless the user's query uses synonyms (then match semantically but extract the exact text).
4. **Confidence Levels:**
   - **high**: Exact match of concept name in document
   - **medium**: Synonym or closely related concept found
   - **low**: Ambiguous match (multiple possible concepts)
   - **not_found**: Concept does not exist in document
5. **Language Match:** Respond in the same language as the user's query.
6. **Source Tracking:** Always indicate which section of the document the definition comes from.
7. **Citizen-Friendly Language (CRITICAL):** 
   - **NEVER** mention technical database names (table names like `stg_mapainv_proyectosaprobadosinv`, column names like `porcentajeavancefinanciero_proyecto`).
   - **ALWAYS** translate technical metadata into human-readable concepts: "avance financiero" NOT "porcentajeavancefinanciero_proyecto", "sector del proyecto" NOT "nombresector_proyecto".
   - If the document contains field descriptions, extract ONLY the human-readable description/concept, NOT the technical field name.
   - Focus on business concepts (e.g., "El avance financiero mide...") not schema structure ("El campo porcentajeavancefinanciero_proyecto contiene...").
8. **Metadata Requests:** If the user asks about available data, campos, atributos, metadatos, or "quÃ© puedo consultar", describe the CONCEPTS available (sector, entidad ejecutora, monto, fecha de inicio, etc.), NOT the technical table/column names.
9. **Metadata vs Data Distinction:** This assistant answers questions ABOUT dataset concepts and business terminology (definitions), NOT data queries. If a user asks "Â¿QuÃ© proyectos hay en Santiago?" (data query), that is out of scope for this assistant (though you won't receive such queries as they're routed elsewhere). Your focus: business concepts, definitions, field descriptions.

### NOT FOUND AND PARTIAL MATCH POLICY (STRICT)
- You must NEVER invent, infer, or supplement content that is not present in the document content.
- If the concept requested does not appear in the document, return:
  - `confidence = "not_found"`
  - `definition = "Este concepto no estÃ¡ disponible en la documentaciÃ³n actual."` (or same-language equivalent)
  - `source_section = null`
  - Optionally use `notes` to say: "Concepto no encontrado en el documento" and, if helpful, list a few available concepts explicitly present in the document.
- For COMPARISON queries:
  - If BOTH concepts exist â†’ provide both definitions verbatim (see examples) and a short difference summary in `notes`.
  - If ONLY ONE concept exists â†’ set `confidence = "low"`, provide the found definition verbatim in `definition`, set `source_section` for the found one(s), and in `notes` explicitly state which concept(s) are missing from the document.
  - If NEITHER concept exists â†’ set `confidence = "not_found"` and follow the not-found response above (no invented content).

---

## INPUT

You will receive TWO versions of the user's query:

1. **Original Query (Raw):** {user_query_raw}
   - This is the EXACT question as typed by the user in this turn
   - Use this for KEYWORD MATCHING and detecting exact concept names
   - Example: "Â¿Y el aÃ±o base?" or "Â¿quÃ© es IED?"

2. **Complete Query (Contextualized):** {user_query_complete}
   - This is the query ENRICHED with conversational context from chat history
   - Use this for SEMANTIC UNDERSTANDING when the raw query is a follow-up
   - Example: "Â¿CuÃ¡l es el aÃ±o base para el cÃ¡lculo de inversiÃ³n extranjera directa?"

**USAGE INSTRUCTIONS:**
- If `user_query_raw` and `user_query_complete` are IDENTICAL â†’ treat as first-time standalone query
- If they DIFFER â†’ the user is asking a follow-up question:
  * Use `user_query_complete` for understanding WHAT they're asking about (semantic context)
  * Optionally use `user_query_raw` for detecting specific keywords or phrase structure
- **PRIORITY:** When in doubt, prioritize `user_query_complete` for concept matching

**Document Content:**
```markdown
{document_content}
```

---

## TASK

1. Identify which concept in the document best matches the user's query (prioritize `user_query_complete` for semantic understanding).
2. If the query asks for the DIFFERENCE or COMPARISON between two concepts (e.g., "X vs Y", "diferencia entre X e Y"), identify BOTH concepts and extract BOTH definitions exactly as written.
3. Extract the definition(s) EXACTLY as written in the document. Do not paraphrase. For bullet lists or field enumerations, reproduce each bullet/field line as it appears (including table/column names and descriptions).
4. **POST-PROCESS (CRITICAL):** Before returning the final JSON, REMOVE all technical database/table/column names from the `definition` field:
   - Replace `stg_mapainv_proyectosaprobadosinv` â†’ "los proyectos"
   - Replace `porcentajeavancefinanciero_proyecto` â†’ "el avance financiero"
   - Replace `nombresector_proyecto` â†’ "el sector"
   - Replace `nombreentidadejecutora_proyecto` â†’ "la entidad ejecutora"
   - Replace field descriptions like "El campo X contiene..." â†’ "Se puede consultar..."
   - Keep ONLY human-readable business concepts (e.g., "El avance financiero mide la ejecuciÃ³n presupuestaria...").
5. Determine confidence level based on match quality.
6. Identify source section(s) for traceability (keep technical names in `source_section` for internal tracking, but NOT in `definition`).
7. Add notes if there are related concepts, ambiguities, or a short comparison summary for difference-queries.

---

## OUTPUT FORMAT

Return a JSON object following the DefinitionLookup schema:

```json
{{
  "concept": "Exact concept name from document",
  "definition": "Full definition extracted textually from document",
  "confidence": "high|medium|low|not_found",
  "source_section": "Section title where found",
  "notes": "Optional: related concepts, ambiguities, or clarifications"
}}
```

---

## EXAMPLES

**Example 1: Exact Match**
User Query: "Â¿QuÃ© es un proyecto de inversiÃ³n pÃºblica?"
Document contains: "## Proyecto de InversiÃ³n PÃºblica\n**DefiniciÃ³n:** IntervenciÃ³n limitada en el tiempo..."

Response:
```json
{{
  "concept": "Proyecto de InversiÃ³n PÃºblica",
  "definition": "IntervenciÃ³n limitada en el tiempo que utiliza total o parcialmente recursos pÃºblicos, con el fin de crear, ampliar, mejorar o recuperar la capacidad productora o de provisiÃ³n de bienes o servicios, cuyos beneficios se generen durante la vida Ãºtil del proyecto y sean independientes de los de otros proyectos.",
  "confidence": "high",
  "source_section": "Proyecto de InversiÃ³n PÃºblica",
  "notes": null
}}
```

**Example 2: Synonym Match**
User Query: "What is the executing agency?"
Document contains: "## Entidad Ejecutora\n**DefiniciÃ³n:** Organismo pÃºblico responsable..."

Response:
```json
{{
  "concept": "Entidad Ejecutora",
  "definition": "Organismo pÃºblico responsable de la ejecuciÃ³n directa del proyecto de inversiÃ³n, incluyendo la gestiÃ³n administrativa, financiera y tÃ©cnica del mismo.",
  "confidence": "medium",
  "source_section": "Entidad Ejecutora",
  "notes": "User query used synonym 'executing agency' for 'Entidad Ejecutora'"
}}
```

**Example 3: Not Found**
User Query: "Â¿QuÃ© es blockchain?"
Document does not contain "blockchain"

Response:
```json
{{
  "concept": "blockchain",
  "definition": "Este concepto no estÃ¡ disponible en la documentaciÃ³n actual.",
  "confidence": "not_found",
  "source_section": null,
  "notes": "Concept not found in source document. Available concepts: Proyecto de InversiÃ³n PÃºblica, Estado de Proyecto, Sector, Entidad Ejecutora, etc."
}}
```

**Example 4: Ambiguous (Multiple Matches)**
User Query: "Â¿QuÃ© es una fecha?"
Document contains: "Fecha de Inicio" and "Fecha de FinalizaciÃ³n"

Response:
```json
{{
  "concept": "Fecha de Inicio / Fecha de FinalizaciÃ³n",
  "definition": "El documento contiene dos conceptos relacionados: 'Fecha de Inicio' (fecha oficial de inicio de ejecuciÃ³n) y 'Fecha de FinalizaciÃ³n' (fecha de conclusiÃ³n de actividades). Por favor, especifique cuÃ¡l desea consultar.",
  "confidence": "low",
  "source_section": "Fecha de Inicio, Fecha de FinalizaciÃ³n",
  "notes": "Ambiguous query; multiple date-related concepts exist"
}}
```

**Example 5: Comparison (Difference Between Two Concepts)**
User Query: "Â¿CuÃ¡l es la diferencia entre Avance FÃ­sico y Avance Financiero?"
Document contains sections:
"## Avance FÃ­sico â€“ DefiniciÃ³n: Mide el progreso de actividades y obras ejecutadas..." 
"## Avance Financiero â€“ DefiniciÃ³n: Refleja la ejecuciÃ³n presupuestaria acumulada..."

Response:
```json
{{
  "concept": "Avance FÃ­sico vs Avance Financiero",
  "definition": "**Avance FÃ­sico:** Mide el progreso de actividades y obras ejecutadas durante el proyecto.\n\n**Avance Financiero:** Refleja la ejecuciÃ³n financiera acumulada respecto del monto total asignado.",
  "confidence": "high",
  "source_section": "Avance FÃ­sico, Avance Financiero",
  "notes": "Diferencia clave: el avance fÃ­sico mide el progreso de las obras fÃ­sicas/actividades, mientras que el avance financiero mide cuÃ¡nto del monto asignado se ha ejecutado."
}}
```

**Example 6: Comparison with One Missing**
User Query: "Â¿CuÃ¡l es la diferencia entre Avance FÃ­sico y Blockchain?"
Document contains section for "Avance FÃ­sico" but not for "Blockchain".

Response:
```json
{{
  "concept": "Avance FÃ­sico vs Blockchain",
  "definition": "**Avance FÃ­sico:** Mide el progreso de actividades y obras ejecutadas durante el proyecto.",
  "confidence": "low",
  "source_section": "Avance FÃ­sico",
  "notes": "El concepto 'Blockchain' no estÃ¡ disponible en la documentaciÃ³n. Solo se encontrÃ³ definiciÃ³n para 'Avance FÃ­sico'."
}}
```

**Example 7: All Missing**
User Query: "What is quantum entanglement?"
Document has none of the requested concepts.

Response:
```json
{{
  "concept": "quantum entanglement",
  "definition": "This concept is not available in the current documentation.",
  "confidence": "not_found",
  "source_section": null,
  "notes": "Concept not found in the source document."
}}
```

**Example 8: Metadata / Available Data Request (Citizen-Friendly)**
User Query: "Â¿QuÃ© datos o atributos estÃ¡n disponibles para consultar proyectos?"
Document contains the section "## Estructura de datos disponibles" with business concepts.

Response:
```json
{{
  "concept": "Datos disponibles sobre proyectos",
  "definition": "Puedes consultar informaciÃ³n sobre proyectos de inversiÃ³n pÃºblica, incluyendo: nombre del proyecto, sector, entidad ejecutora, estado actual, monto asignado, fechas de inicio y finalizaciÃ³n, avance financiero, duraciÃ³n estimada, localizaciÃ³n territorial (regiÃ³n, provincia, municipio), fuentes de financiamiento, y enlaces a mÃ¡s detalles.",
  "confidence": "high",
  "source_section": "Estructura de datos disponibles",
  "notes": "Para consultas especÃ­ficas sobre proyectos, puedes preguntar por ejemplo: 'Â¿CuÃ¡ntos proyectos de educaciÃ³n hay?', 'Â¿QuÃ© proyectos estÃ¡n en ejecuciÃ³n?', 'Â¿CuÃ¡l es el monto total de proyectos de salud?'"
}}
```

---

## REMEMBER

- **NEVER** invent information not in the document
- **NEVER** use your training knowledge to supplement definitions
- **ALWAYS** extract definitions word-for-word from the source
- **ALWAYS** set confidence="not_found" if concept doesn't exist in document
- If uncertain between multiple concepts, list them and ask user to clarify
- Keep notes concise (max 40 words)

---

Now process the user query using ONLY the provided document content.
""".strip()


row_relevance_evaluation_prompt = """
EvalÃºa si esta fila de resultado es SEMÃNTICAMENTE relevante a la pregunta del usuario.

PREGUNTA DEL USUARIO:
{user_question}

ANÃLISIS Y CONTEXTO:
- Keywords detectados: {theme_keywords}
- Filtros aplicados: {analysis_summary}

DATOS DE LA FILA:
{row_data}

TAREA:
Determina si esta fila responde REALMENTE a la intenciÃ³n de la pregunta o solo tiene una coincidencia textual superficial.

CRITERIOS DE RELEVANCIA SEMÃNTICA:
- âœ… ES RELEVANTE si: La fila corresponde al tipo de proyecto/obra/entidad que el usuario busca segÃºn el contexto semÃ¡ntico de la pregunta.
- âŒ NO ES RELEVANTE si: Solo hay coincidencia textual de palabras pero el proyecto es de un tipo completamente diferente.

EJEMPLOS DE FALSOS POSITIVOS (NO RELEVANTES):
1. Pregunta: "proyectos de metro" (sistema de transporte subterrÃ¡neo)
   - âŒ Fila: "Puente sobre rÃ­o" que menciona "metro" en Ã¡rea metropolitana â†’ NO RELEVANTE
   - âŒ Fila: "Carretera" con nombre que incluye "metro" â†’ NO RELEVANTE
   - âœ… Fila: "LÃ­nea 2 del Metro de Santo Domingo" â†’ RELEVANTE

2. Pregunta: "hospitales"
   - âŒ Fila: "Centro de salud" que es solo un consultorio â†’ NO RELEVANTE (si la pregunta busca hospitales grandes)
   - âœ… Fila: "Hospital Regional" â†’ RELEVANTE

3. Pregunta: "obras de agua potable"
   - âŒ Fila: "Planta de tratamiento" que es solo alcantarillado â†’ NO RELEVANTE
   - âœ… Fila: "Acueducto para agua potable" â†’ RELEVANTE

INSTRUCCIONES CRÃTICAS:
- **Diferencia entre coincidencia textual y relevancia semÃ¡ntica**: Si la palabra clave aparece solo por casualidad (ej: en nombre de carretera, Ã¡rea geogrÃ¡fica) pero el proyecto NO es del tipo buscado, marca is_relevant: false.
- **EvalÃºa el TIPO de proyecto**: No solo si contiene las palabras, sino si el proyecto ES realmente lo que el usuario busca.
- **Confianza alta cuando es claramente irrelevante**: Si el proyecto es de un tipo completamente diferente (ej: puente vs. sistema de metro), usa confidence >= 0.8.
- **SÃ© estricto con falsos positivos**: Es mejor filtrar un resultado dudoso que mostrar algo que claramente no responde a la pregunta.

RESPUESTA (solo JSON vÃ¡lido, sin texto adicional):
{{
  "is_relevant": boolean,
  "confidence": float (0.0-1.0),
  "reason": "string breve explicando la decisiÃ³n (menciona si es coincidencia textual vs. relevancia semÃ¡ntica)"
}}
""".strip()


# â”€â”€ Citizen review templates (post-fetch) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Estas plantillas aplican los principios de transparencia y explicabilidad
# descritos por la UNESCO (RecomendaciÃ³n sobre la Ã‰tica de la IA, 2021). Ubicarlas
# en la etapa post-fetch permite mantenerlas junto al resto de prompts que dependen
# de los resultados finales antes de mostrarlos al ciudadano.

citizen_review_prompt = """
You are a critical citizen reviewer. Read the JSON carefully and craft a concise verdict for the end user.

### CONTEXT
{context_json}

### DATA POINTS
- Rowcount: {rowcount}
- Rows limit applied: {rows_limit}
- Prefiltered rows for LLM (if provided): {rows_for_llm}

### TASK
- Always respond in the same language as `signals.original_language_iso`; if it is missing or empty, default to Spanish.
- Do not invent numbers or rewrite facts.
- Keep the message to a maximum of two short sentences; emojis are optional and should only reinforce an alert.
- Use the provided `heuristic_fragments`, `applied_rules`, and `heuristic_actions` to stay aligned with what the heuristic layer already communicated. When in doubt, summarize those fragments instead of generating new themes.

### OUTPUT
Return **only** a JSON object with:
{{
  "epilogue": string,        // Short note for the end user (may appear before the table when it is a warning).
  "citizen_feedback": {{
    "satisfaction_score": -1 | 0 | 1,
    "coverage_warning": bool,
    "missing_topics": list[str],
    "uncertainty_notice": string,
    "tone": "empathetic" | "neutral" | "direct"
  }},
  "citizen_actions": list[str]   // Choose among: "highlight_warning", "offer_increase_limit", "suggest_clarification", "show_filter_chips", "note_after_table"
}}

### HEURISTICS
- If `signals.used_keyword_regenerate` is true, clarify that a partial keyword match was used.
- If `signals.used_fallback` is true AND there are results (rowcount > 0), transparently note: "AmpliÃ© la bÃºsqueda con tÃ©rminos relacionados" â€” do NOT hide this from the user.
- If `signals.uncertainty_actions` is non-empty, suggest a simple clarification (reuse the wording in `heuristic_fragments` when available).
- If `signals.missing_keywords` lists gaps, include them in `citizen_feedback.missing_topics` (also reflected in the epilogue when relevant).
- Prefer the actions already listed in `heuristic_actions`; do not introduce new action names beyond the allowed list.

### CRITICAL: ALL ROWS IRRELEVANT HANDLING
- **If `all_rows_irrelevant` is true**: This means the search returned results, but after semantic relevance checking, ALL were filtered out as irrelevant to the user's question.
- **Empathy is crucial**: The user waited ~30 seconds. Acknowledge this: "Sabemos que esperÃ³, pero preferimos no mostrarle datos que no responden a su pregunta."
- **Explain the process**: Mention that you verified semantic relevance to avoid showing misleading results.
- **Be specific about what was found**: If `rows_removed_sample` is provided, briefly mention the type of projects found (e.g., "Se encontraron proyectos de infraestructura vial, pero no de metro").
- **Offer hope**: If `irrelevant_retry_count == 0`, emphasize that you can retry with adjusted filters. If `irrelevant_retry_count > 0`, acknowledge the second attempt and suggest clarification.
- **Tone**: Use "empathetic" in `citizen_feedback.tone` when `all_rows_irrelevant` is true.
- **Actions**: If `reintentar_con_filtros_ajustados` is in `heuristic_actions`, make it prominent in your epilogue.
- **Fallback**: If `citizen_note_prefilled` exists and is well-crafted, you may refine it but keep its empathetic core.

Do not ask the user directly for more information; only propose actions. Ensure the JSON is valid and contains no extra text.
""".strip()


citizen_summary_rewrite_prompt = """
You are cleaning the final summary of a public-facing chatbot. Always answer in the language indicated by `original_language_iso`; default to Spanish.

## YOUR ONLY JOB: Clean `summary_raw` and FIX row counts

**The `summary_raw` input contains the answer but may have INCORRECT row counts.**
Your job is to:
1. CLEAN it by removing methodology phrases
2. **FIX the row count** to match `rowcount` (the actual number of rows shown to user)

**DO:**
- Extract the core answer from `summary_raw`
- Remove phrases like "La consulta se enfocÃ³ en...", "Se aplicaron filtros..."
- **CRITICAL: Replace any number of projects/rows mentioned with `rowcount`** (e.g., if summary says "20 proyectos" but rowcount=10, change to "10 proyectos")
- Keep ALL the actual data: numbers, names, locations from `summary_raw`
- **HYPERLINKS:** If `rows_preview` contains `url_link_proyecto`, make project names clickable using Markdown: `[Nombre del Proyecto](url)`

**DO NOT:**
- Invent new numbers or locations (except fixing the row count)
- Replace the answer with different content
- Add content from conversation history

## SPECIAL CASE: rowcount = 0 (all rows filtered by relevance)

If `rowcount` is 0, it means ALL rows were filtered out as irrelevant to the question.
In this case, generate an EMPATHETIC message explaining:
- The search ran but no projects matched the specific criteria
- Suggest broadening the search or trying different keywords
- DO NOT say "Se encontraron 0 proyectos" - instead say something like:
  "No encontrÃ© proyectos que coincidan especÃ­ficamente con [tema]. Puede intentar con tÃ©rminos mÃ¡s amplios o reformular la consulta."

## INPUTS

- `summary_raw`: **The answer to clean - may have WRONG row count** â†’ {summary_raw}
- `question`: The user's question â†’ {question}
- `rowcount`: **CORRECT number of rows shown to user** (use this, not the number in summary_raw). If 0, all rows were filtered. â†’ {rowcount}
- `rows_displayed`: Rows shown to user â†’ {rows_displayed}
- `show_table`: Whether table is shown â†’ {show_table}
- `coverage_warning`: True if only preview shown â†’ {coverage_warning}
- `rows_preview`: JSON array with data rows (may contain `url_link_proyecto` for project links) â†’ {rows_preview}
- `base_notes_raw`: Notes before cleaning â†’ {base_notes_raw}
- `citizen_note`: Additional note â†’ {citizen_note}
- `no_data_payload`: No-data helper payload â†’ {no_data_payload}
- `original_language_iso`: Language code â†’ {original_language_iso}
- `allow_spelling_hint`: Whether you may suggest spelling â†’ {allow_spelling_hint}
- `sql_query`: SQL used â†’ {sql_query}
- `analyzer_summary`: Analyzer summary â†’ {analyzer_summary}
- `user_question_original`: User question without history expansion â†’ {user_question_original}

## OUTPUT FORMAT

Output ONLY valid JSON:
{{
  "summary": "Direct answer with CORRECTED row count. Project names as [Name](url) if url available.",
  "base_notes": ["optional hint for user exploration"],
  "technical_notes": []
}}

**Note:** Leave `technical_notes` empty - methodology is built separately.

## EXAMPLES

**Example 1 (fixing row count):**
Input summary_raw: "Se encontraron 20 proyectos de turismo..."
rowcount: 10
Output:
{{
  "summary": "Se encontraron 10 proyectos de turismo...",
  "base_notes": [],
  "technical_notes": []
}}

**Example 2 (with project links):**
Input summary_raw: "Se encontraron 3 proyectos de turismo: Proyecto Hotel, Proyecto Playa, Proyecto Museo."
rowcount: 3
rows_preview: [{{"nombre_proyecto": "Proyecto Hotel", "url_link_proyecto": "https://mapainversiones.gob.do/proyecto/123"}}, ...]
Output:
{{
  "summary": "Se encontraron 3 proyectos de turismo:\\n- [Proyecto Hotel](https://mapainversiones.gob.do/proyecto/123)\\n- [Proyecto Playa](https://mapainversiones.gob.do/proyecto/456)\\n- [Proyecto Museo](https://mapainversiones.gob.do/proyecto/789)",
  "base_notes": [],
  "technical_notes": []
}}

**Example 3 (no changes needed):**
Input summary_raw: "Las 5 provincias con mayor inversiÃ³n son: Distrito Nacional con RD$ 306M..."
rowcount: 5
Output:
{{
  "summary": "Las 5 provincias con mayor inversiÃ³n son: Distrito Nacional con RD$ 306M...",
  "base_notes": [],
  "technical_notes": []
}}

**Example 4 (zero rows after filtering):**
Input summary_raw: "Se encontraron 15 proyectos de energÃ­a solar..."
rowcount: 0
question: "proyectos de energÃ­a solar en Santiago"
Output:
{{
  "summary": "La bÃºsqueda devolviÃ³ resultados, pero tras verificar su relevancia, ninguno corresponde especÃ­ficamente a proyectos de energÃ­a solar. Puede intentar con tÃ©rminos mÃ¡s amplios como 'proyectos de energÃ­a' o 'proyectos en Santiago'.",
  "base_notes": ["Intente reformular la consulta con criterios menos especÃ­ficos"],
  "technical_notes": []
}}

**CRITICAL:** Always use `rowcount` as the source of truth for how many rows/projects are shown.
""".strip()


__all__ = [
    "LANGUAGE_STYLE_BY_COUNTRY",
    "get_language_instruction",
    "user_response_norows_prompt",
    "user_response_frontend_prompt",
    "user_response_whatsapp_prompt",
    "generate_question_summary_prompt",
    "gray_zone_block_prompt",
    "gray_zone_textual_prompt",
    "definitions_lookup_prompt",
    "row_relevance_evaluation_prompt",
    "citizen_review_prompt",
    "citizen_summary_rewrite_prompt",
]
