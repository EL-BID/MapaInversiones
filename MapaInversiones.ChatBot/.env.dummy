# Copy this file to .env and fill the values.
# Do NOT commit real secrets.

#define el entorno de ejecucion: development, production
ENV="production"

# ========================================
# Host resource budgeting (target ~75% utilization)
# ========================================
# Establece manualmente cuantos cores y GB tiene la maquina para estimar limites.
# Todos los componentes deben trabajar con este presupuesto y el porcentaje de uso objetivo.
HOST_CPU_CORES=8
HOST_MEMORY_GB=30
# Porcentaje del total de recursos que queremos dedicar al servicio principal (CPU, memoria).
RESOURCE_UTILIZATION_PERCENT=80

# Estimacion "por worker" para que Gunicorn no abra mas procesos de los que caben.
GUNICORN_WORKER_MEMORY_ESTIMATE_GB=1

# Si quieres sobredimensionar el hilo/worker en un entorno especifico pon el porcentaje deseado;
# por defecto se toma el RESOURCE_UTILIZATION_PERCENT (ej: 75%).
GUNICORN_WORKERS_PERCENT=80
GUNICORN_THREADS_PER_WORKER=4

# ========================================

#ENFORCE_FRONTEND_REFERRER=0
#FRONTEND_ALLOWED_REFERRERS=http://localhost:8000,http://127.0.0.1:8000

# Gunicorn tuning (opcional; si se omiten, gunicorn.conf.py usa defaults segun ENV/CPU)
# GUNICORN_WORKERS=4
# GUNICORN_WORKER_CONNECTIONS=400
# GUNICORN_THREADS=1
# GUNICORN_RELOAD=false

# Database pool tuning (opcional; si se omite, se ajusta por entorno)
# POSTGRES_POOL_SIZE=20
# POSTGRES_MAX_OVERFLOW=30
# POSTGRES_POOL_TIMEOUT=30

EMBEDDING_MODEL="text-embedding-3-small"
TRACING_ENDPOINT="http://phoenix:6006/v1/traces"
ARIZE_ENABLED=0
OPENAI_MODEL_MODERATION="omni-moderation-latest"
OPENAI_MODERATION_API_KEY="replace_me"

# Model Cloud Selector (AZURE, OPENAI)
CLOUD_SELECTOR="AZURE"

# Original OPENAI Models Setup
OPENAI_API_KEY="replace_me"
OPENAI_MODEL="gpt-4o"
OPENAI_MODEL_MINI="gpt-4o-mini"

# AZURE Endpoint
# https://portal.azure.com/#view/Microsoft_Azure_ProjectOxford/CognitiveServicesHub/~/OpenAI
AZURE_OPENAI_API_KEY="replace_me"
AZURE_OPENAI_ENDPOINT="https://example.openai.azure.com/"
AZURE_OPENAI_API_VERSION="2024-12-01-preview"

# PRD example
# client = AzureOpenAI(
#    api_version="2024-12-01-preview",
#    azure_endpoint="https://example.openai.azure.com/",
# )

# https://example.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15
# EMBEDDINGS:
# endpoint = "https://example.openai.azure.com/"
# model_name = "text-embedding-3-small"
# deployment = "text-embedding-3-small"
# api_version = "2024-02-01"

# AZURE Models
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_4="gpt-4o"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_4_MODEL="gpt-4o"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_4MINI="gpt-4o-mini"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_4MINI_MODEL="gpt-4o-mini"

# gpt-4.1-mini
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_41MINI="gpt-4.1-mini"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_41MINI_MODEL="gpt-4.1-mini"
AZURE_OPENAI_API_VERSION_41MINI="2024-12-01-preview"

# gpt-5-mini
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_5="gpt-5-mini"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_5_MODEL="gpt-5-mini"
AZURE_OPENAI_API_VERSION_5="2024-12-01-preview"

# AZURE Embedding Models
AZURE_OPENAI_EMBEDDING_NAME="text-embedding-3-small"
AZURE_OPENAI_EMBEDDING_DIMENSIONS=1536

# AZURE DB connection (example)
# 0.0.0.0,1433
# database_name
# user:password
AZURE_SQL_HOST="0.0.0.0,1433"
AZURE_SQL_DATABASE="database"
AZURE_SQL_USERNAME="user"
AZURE_SQL_PASSWORD="password"

# AZURE AISearch
AZURE_SEARCH_ENDPOINT="https://example-search.search.windows.net"
AZURE_SEARCH_INDEX="example-index"
AZURE_SEARCH_API_KEY="replace_me"
AZURE_SEARCH_SEMANTIC_CONFIG="semanticsql01"

# Azure Postgres (preferred) - fill secret into POSTGRES_PASSWORD below
# Example legacy connection hint: host=example.postgres.database.azure.com port=5432 dbname=postgres user=app_user connect_timeout=10 sslmode=prefer
POSTGRES_HOST="localhost"
POSTGRES_PORT=5432
POSTGRES_DATABASE="chatbot"
POSTGRES_USER="user"
# Do NOT store plaintext secrets in repo if you can avoid it. Replace the placeholder interactively.
POSTGRES_PASSWORD="password"
POSTGRES_SSLMODE=require

# Previous / fallback (commented out)
# POSTGRES_HOST=127.0.0.1
# POSTGRES_PORT=5432
# POSTGRES_DATABASE="chatbot"
# POSTGRES_USER="postgres"
# POSTGRES_PASSWORD="password"

# Flags using booleans
MIDDLEWARE_OPENAI_MODERATION=false

# Session
# Cookie / session timing in seconds
SESSION_SECRET_KEY="change_me"
SESSION_MAX_AGE=31536000        # Vida util maxima de la cookie (~1 year)
SESSION_MAX_TIME=86400          # Ventana para "perdonar" el limite (24h). Si pasa este tiempo se resetea count.
SESSION_MAX_QUESTION=10         # Preguntas permitidas por sesion antes de bloquear nuevas consultas.
SESSION_MAX_HISTORY_LENGTH=10   # Turnos que se envian al grafo por request; el resto queda persistido en DB.
SESSION_MANTAIN_QUESTIONS=false # True = guarda todo el historial en session["history"]. False = solo el ultimo par user/bot.
# Force cookies to be HTTPS-only? (set to false when testing via http://localhost)
SESSION_COOKIE_SECURE=false

# FBK
FACEBOOK_WEBHOOK_VERIFY_TOKEN="replace_me"
FACEBOOK_WHATSAPP_TOKEN="replace_me"
FACEBOOK_WHATSAPP_API_URL="https://graph.facebook.com/v20.0/"
FACEBOOK_APP_SECRET="replace_me"

# GRAPH BEHAVIOR
GRAPH_RECURSION_LIMIT=20

# GOOGLE
GOOGLE_APPLICATION_CREDENTIALS_PATH="path/to/credentials.json"
GOOGLE_TRANSLATE_FLAG=false

# FRONTEND API KEY
FRONTEND_API_KEY="replace_me"
# IF SET TO 1, FRONTEND MUST SEND THE API KEY IN REQUEST HEADERS
REQUIRE_FRONTEND_API_KEY=0

# CACHE ENABLE
CACHE_ENABLED=true

# REASONING MODEL PARAMETERS
REASONING_EFFORT_SQL=high
REASONING_VERBOSITY_SQL=low
REASONING_EFFORT_TEXT=medium
REASONING_VERBOSITY_TEXT=medium

# RETRIEVAL THRESHOLDS
SEMANTIC_DISTANCE_THRESHOLD=0.35
SEMANTIC_DISTANCE_RELAX_STEP=0.05
KEYWORD_MIN_RANK=0.05
KEYWORD_RANK_RELAX_STEP=0.02

# ANALYZER SETTINGS
# (el valor se define mas abajo en Prefetch Stage)
# ANALYZER_FILTER_CONFIDENCE_THRESHOLD=0.8

ENABLE_COMPLEXITY_ROUTING=false
FILTER_CONFIDENCE_THRESHOLD=0.8
USE_UNIFIED_INBOX=true
ENABLE_ANALYZER_GRAY_ZONE=true

# ========================================
# Territorial Disambiguation Configuration
# ========================================
# Habilita desambiguacion territorial para evitar falsos positivos
#
# COMPORTAMIENTO CON FLAG=false (LEGACY - DEFAULT):
# - Usa OR triple: WHERE (nombre_region OR nombre_departamento OR nombre_municipio) ILIKE '%valor%'
# - Mezcla todos los niveles territoriales (region, provincia/departamento, municipio)
# - Ejemplo: "Santo Domingo" retorna provincia + 4 municipios (39% falsos positivos)
# - Backward compatible con sistema actual
#
# COMPORTAMIENTO CON FLAG=true (NUEVO):
# - Consulta dim_territorios_flat para detectar ambiguedad
# - Si territorio es UNICO: usa columna especifica (ej: WHERE nombre_departamento = 'LA ROMANA')
# - Si territorio es AMBIGUO:
#   * Politica por defecto: NO aplica filtro territorial, marca para clarificacion
#   * Usuario ve opciones en UI para seleccionar nivel deseado
#   * Sidebar muestra transparencia: "Filtro: Provincia X, tambien existe Municipio X"
# - Si usuario menciona nivel explicito (ej: "provincia de Santiago"):
#   * Resuelve directamente sin entrar en desambiguacion
# - Elimina falsos positivos: 0% vs 39% actual
#
# POLITICA DE AMBIGUEDAD (cuando flag=true y hay multiples niveles):
# - Por defecto: NO filtrar territorio, pedir clarificacion al usuario
# - Alternativa (comentada): Usar nivel mas agregado (provincia) con nota de transparencia
#
# RECOMENDACION:
# - Staging/Testing: true (validar nuevo comportamiento)
# - Production: false inicialmente, luego true despues de validacion
USE_TERRITORIAL_DISAMBIGUATION=true

# ========================================
# NUEVAS PALANCAS DE CONFIGURACION (Diciembre 2025)
# ========================================
# Copia estas variables a tu .env y ajusta segun necesidad

# ========================================
# Territorial Disambiguation
# ========================================
# Maximo de opciones territoriales en prompt de desambiguacion
# Recomendado: 5 (evita sobrecargar al usuario con demasiadas opciones)
TERRITORIAL_MAX_OPTIONS=3

# ========================================
# Uncertainty Topics (Business Logic Control)
# ========================================
# Topics que BLOQUEAN el flujo y requieren clarificacion del usuario
# ANTES de generar SQL. Solo territorios genericos ("mi provincia")
# y preguntas incompletas son bloqueantes.
# Formato: lista separada por comas, sin espacios
# Valores validos: pregunta_incompleta, territorio_ambiguo, valor_ambiguo,
#                  year_scope, territorio, proxy_avance, pregunta_general
BLOCKING_UNCERTAINTY_TOPICS=pregunta_incompleta,territorio_ambiguo

# Topics que generan warning pero NO bloquean - el sistema continua con defaults
# y citizen_review puede sugerir alternativas post-fetch
# Formato: lista separada por comas
NON_BLOCKING_UNCERTAINTY_TOPICS=valor_ambiguo,year_scope,territorio,proxy_avance,pregunta_general

# ========================================
# Prefetch Stage (Analyzer & Memory)
# ========================================
# Confianza minima para conservar filtros sugeridos por el analyzer
ANALYZER_FILTER_CONFIDENCE_THRESHOLD=0.7
# Umbral de similitud para fuzzy matching de catalogos (sector, entidad, territorio)
FUZZY_MATCH_THRESHOLD=0.7
# Maximo de caracteres del historial que viaja al prompt (balance tokens vs. contexto)
HISTORY_TRUNCATE_CHARS=5000
# Consultas consecutivas sin datos antes de sugerir contacto humano
FRUSTRATION_THRESHOLD=2

# ========================================
# Fetch Stage (SQL generation & execution)
# ========================================
# Limite de filas por respuesta tabular (antes de pedir "ver mas")
SQL_ROWS_LIMIT=10
# Rango de anos por defecto cuando solo dicen "proyectos 2024"
SQL_DEFAULT_YEAR_RANGE=5
# Columna monetaria por defecto cuando no se especifica (valor_proyecto/ejecutado/vigente)
SQL_DEFAULT_VALUE_COLUMN=valor_proyecto
# Maximo de keywords usados en busquedas SQL libres (resto lo cubre FlashRank)
MAX_SQL_KEYWORDS=3
# Maximo de columnas targets en busquedas textuales
MAX_SQL_COLUMNS=2
# Orden de prioridad de columnas textuales para busquedas libres
SQL_PRIORITY_COLUMNS='["nombre_proyecto","objetivo_proyecto"]'
# Maximo de reintentos de generacion SQL antes de fallar
SQL_MAX_RETRIES=2
# Timeout por llamada LLM (segundos)
LLM_REQUEST_TIMEOUT=90
# Reintentos internos del SDK de OpenAI por error transitorio
LLM_MAX_RETRIES=2
# Timeout total del safe_invoke sumando reintentos (segundos)
SAFE_INVOKE_MAX_TIME=120
# Semaforo global: maximo de llamadas LLM concurrentes permitidas
# (el valor efectivo se define mas abajo en el bloque de legacy)

# ========================================
# Postfetch Stage (Citizen review & tables)
# ========================================
# Activa filtro semantico con LLM en citizen review
FEATURE_FILTER_ROWS_LLM=true
# Maximo de filas que revisa el LLM despues de FlashRank
ROWS_LLM_MAX=10
# Confianza minima para que el LLM deje pasar una fila (0-1)
ROWS_LLM_THRESHOLD=0.6

# Activa el re-ranker FlashRank previo al filtro LLM
FEATURE_FLASHRANK_CITIZEN=true
# Score minimo FlashRank para considerar "HIGH" (se acepta sin LLM)
FLASHRANK_HIGH_THRESHOLD=0.70
# Score maximo para considerar "LOW" (se descarta sin LLM)
FLASHRANK_LOW_THRESHOLD=0.10
# Cantidad de filas "GRAY" que se envian al LLM para revision
FLASHRANK_MAX_LLM_ROWS=5
# Texto minimo (caracteres) para ejecutar FlashRank (si no, se salta)
FLASHRANK_MIN_TEXT_LENGTH=20

# Oculta la tabla si filas <= este valor (y columnas <= HIDE_TABLE_MAX_COLS); 0 = siempre mostrar
HIDE_TABLE_MAX_ROWS=1
# Umbral de columnas para ocultar tabla (junto con filas)
HIDE_TABLE_MAX_COLS=1
# 1 = oculta texto redundante cuando hay tabla, 0 = muestra ambos
HIDE_TEXT_WHEN_TABLE=1

# ========================================
# LLM GUARDRAILS - Concurrency & Resilience
# ========================================
LLM_CONCURRENCY_LIMIT=25
LLM_SEMAPHORE_TIMEOUT_SECONDS=90
LLM_SEMAPHORE_LOG_THRESHOLD_MS=1000
LLM_CIRCUIT_BREAKER_FAIL_MAX=5
LLM_CIRCUIT_BREAKER_RESET_TIMEOUT=30
LLM_GUARDRAIL_RETRY_ATTEMPTS=3
LLM_RETRY_BACKOFF_MAX_SECONDS=16

# ========================================
# POSTGRES POOL - For 100 concurrent users
# Combinacion de la capacidad de la BD (POSTGRES_MAX_CONNECTIONS) y el porcentaje
# de uso objetivo garantiza que la suma de conexiones activas nunca supere ~75% del limite.
# ========================================
POSTGRES_MAX_CONNECTIONS=200
POSTGRES_POOL_PERCENT=75
POSTGRES_OVERFLOW_PERCENT=25
POSTGRES_POOL_SIZE=30
POSTGRES_MAX_OVERFLOW=20
POSTGRES_POOL_TIMEOUT=60

# ========================================
# REQUEST TIMEOUT
# ========================================
REQUEST_TIMEOUT_SECONDS=180

# ========================================
# LLM CONCURRENCY (legacy, tambien usado)
# ========================================
LLM_MAX_CONCURRENCY=25
LLM_QUEUE_TIMEOUT_SECONDS=90

# ========================================
# PGBOUNCER (si no estan, usa defaults del entrypoint.sh)
# Aplicamos el mismo porcentaje de uso (%=75) para no saturar la BD ni la cola de conexiones.
# ========================================
PGBOUNCER_MAX_CLIENT_CONNECTIONS=200
PGBOUNCER_CLIENT_PERCENT=75
PGBOUNCER_DEFAULT_POOL_PERCENT=75
PGBOUNCER_RESERVE_POOL_PERCENT=25
PGBOUNCER_MAX_CLIENT_CONN=150
PGBOUNCER_DEFAULT_POOL_SIZE=30
PGBOUNCER_RESERVE_POOL_SIZE=10
PGBOUNCER_IDLE_TRANSACTION_TIMEOUT=60

# Opciones: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Si esta vacio o no existe, usa el default por entorno:
#   - development -> DEBUG
#   - production -> WARNING
#LOG_LEVEL=DEBUG    # Ver todo (verbose)
#LOG_LEVEL=INFO     # Ver info + warnings + errors
#LOG_LEVEL=WARNING  # Solo warnings y errors (silencioso)
#LOG_LEVEL=ERROR    # Solo errors (muy silencioso)
LOG_LEVEL=INFO

# Habilitar/Deshabilitar Historial Conversacional
ENABLE_HISTORY_CONTEXT=true  # (Antes: nodes_prefetch hardcoded)
# Habilitar/Deshabilitar Memoria de Sesion (filtros, dimensiones)
ENABLE_SESSION_MEMORY_CONTEXT=true  # (Antes: nodes_prefetch hardcoded)
# Ventana de Tiempo para Historial (Segundos)
HISTORY_WINDOW_SECONDS=300  # 5 minutos

# Search Strategy Flags
SEARCH_ENABLE_SEMANTIC=true
SEARCH_ENABLE_TRIGRAM=true
SEARCH_CASCADE_MODE=true
SEARCH_TRIGRAM_THRESHOLD=0.3

# ========================================
# CASCADE SEARCH CONFIGURATION (NEW)
# ========================================
# Nivel 2: Umbral estricto para trigram similarity (typos menores)
SEARCH_TRIGRAM_THRESHOLD_HIGH=0.5

# Nivel 4: Full-Text Search con stemming (vacuna -> vacunacion)
SEARCH_ENABLE_FTS=true
FTS_LANGUAGE=spanish

# Relajar catalogos con ILIKE antes de cascada si exacto falla
CATALOG_RELAX_ENABLED=true
